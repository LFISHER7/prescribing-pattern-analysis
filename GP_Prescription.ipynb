{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Table-of-contents\" data-toc-modified-id=\"Table-of-contents-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Table of contents</a></span></li><li><span><a href=\"#The-Dataset\" data-toc-modified-id=\"The-Dataset-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>The Dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-Exploration\" data-toc-modified-id=\"Data-Exploration-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Data Exploration</a></span></li><li><span><a href=\"#Number-of-Prescriptions-of-a-Specific-Drug\" data-toc-modified-id=\"Number-of-Prescriptions-of-a-Specific-Drug-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Number of Prescriptions of a Specific Drug</a></span></li><li><span><a href=\"#Number-of-Prescription-by-CCG\" data-toc-modified-id=\"Number-of-Prescription-by-CCG-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Number of Prescription by CCG</a></span></li></ul></li><li><span><a href=\"#Normalising-the-Time-Series\" data-toc-modified-id=\"Normalising-the-Time-Series-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Normalising the Time Series</a></span><ul class=\"toc-item\"><li><span><a href=\"#Normalised-Salbutamol-by-CCG\" data-toc-modified-id=\"Normalised-Salbutamol-by-CCG-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Normalised Salbutamol by CCG</a></span></li></ul></li><li><span><a href=\"#Time-Series-Smoothing\" data-toc-modified-id=\"Time-Series-Smoothing-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Time Series Smoothing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Moving-Average\" data-toc-modified-id=\"Moving-Average-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Moving Average</a></span></li><li><span><a href=\"#Savitzky–Golay-Filter\" data-toc-modified-id=\"Savitzky–Golay-Filter-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Savitzky–Golay Filter</a></span></li></ul></li><li><span><a href=\"#Unsupervised-Approach---Hierarchical-Clustering\" data-toc-modified-id=\"Unsupervised-Approach---Hierarchical-Clustering-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Unsupervised Approach - Hierarchical Clustering</a></span><ul class=\"toc-item\"><li><span><a href=\"#Clustering-Salbutamol-by-CCG\" data-toc-modified-id=\"Clustering-Salbutamol-by-CCG-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Clustering Salbutamol by CCG</a></span></li><li><span><a href=\"#Cophenetic-Correlation-Coefficient\" data-toc-modified-id=\"Cophenetic-Correlation-Coefficient-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Cophenetic Correlation Coefficient</a></span></li><li><span><a href=\"#Normalised-Clustering-of-Tramadol\" data-toc-modified-id=\"Normalised-Clustering-of-Tramadol-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Normalised Clustering of Tramadol</a></span></li><li><span><a href=\"#Moving-from-CCG-to-Practice-Level\" data-toc-modified-id=\"Moving-from-CCG-to-Practice-Level-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Moving from CCG to Practice Level</a></span><ul class=\"toc-item\"><li><span><a href=\"#Getting-Practice-Level-Data\" data-toc-modified-id=\"Getting-Practice-Level-Data-5.4.1\"><span class=\"toc-item-num\">5.4.1&nbsp;&nbsp;</span>Getting Practice Level Data</a></span></li></ul></li><li><span><a href=\"#Clustering-at-Individual-Practice-Level\" data-toc-modified-id=\"Clustering-at-Individual-Practice-Level-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>Clustering at Individual Practice Level</a></span><ul class=\"toc-item\"><li><span><a href=\"#Deciding-on-the-Best-K\" data-toc-modified-id=\"Deciding-on-the-Best-K-5.5.1\"><span class=\"toc-item-num\">5.5.1&nbsp;&nbsp;</span>Deciding on the Best K</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# <center>GP Practice Prescribing Pattern Analysis</center>\n",
    "## Table of contents\n",
    "1. **[The Dataset](#The-Dataset)<br/>**\n",
    "      i.[Data Exploration](#Data-Exploration)<br/>\n",
    "      ii.[Number of Prescriptions of a Specific Drug](#Number-of-Prescriptions-of-a-Specific-Drug)<br/>\n",
    "      iii.[Number of Prescriptions by CCG](#Number-of-Prescriptions-by-CCG)\n",
    "2. **[Normalising the Time Series](#Normalising-the-Time-Series)<br/>**\n",
    "      i.[Normalised Salbutamol by CCG](#Normalised-Salbutamol-by-CCG)\n",
    "3. **[Time Series Smoothing](#Time-Series-Smoothing)<br/>**\n",
    "\n",
    "3. **[Unsupervised Approach - Hierarchical Clustering](#Unsupervised-Approach:-Hierarchical-Clustering)<br/>**\n",
    "      i.[Clustering Salbutamol by CCG](#Clustering-Salbutamol-by-CCG)<br/>\n",
    "      ii.[Normalising the Time Series](#Normalising-the-Time-Series)<br/>\n",
    "      a)[Normalised Salbutamol by CCG](#Normalised-Salbutamol-by-CCG)<br/>\n",
    "      b)[Visualising Normalised vs Non-normalised](#Visualising-Normalised-vs-Non-normalised)<br/>\n",
    "      iii.[Normalised Clustering of Tramadol](#Normalised-Clustering-of-Tramadol)<br/>\n",
    "      iv.[Moving From CCG to Practice Level](#Moving-From-CCG-to-Practice-Level)<br/>\n",
    "      a)[Getting Practice Level Data](#Getting-Practice-Level-Data)<br/>\n",
    "      b)[Clustering at Individual Practice Level](#Clustering-at-Individual-Practice-Level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import datetime\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import random\n",
    "import os\n",
    "import seaborn as sns\n",
    "import scipy.cluster.hierarchy as hac\n",
    "import scipy.signal as sc\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import HTML\n",
    "from scipy import stats\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from scipy.spatial.distance import pdist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "The raw code for this IPython notebook is by default hidden for easier reading.\n",
    "To toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>.''')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show_err=false; \n",
    "function code_toggle_err() {\n",
    " if (code_show_err){\n",
    " $('div.output_stderr').hide();\n",
    " } else {\n",
    " $('div.output_stderr').show();\n",
    " }\n",
    " code_show_err = !code_show_err\n",
    "} \n",
    "$( document ).ready(code_toggle_err);\n",
    "</script>\n",
    "To toggle on/off warning messages, click <a href=\"javascript:code_toggle_err()\">here</a>.''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Dataset\n",
    "This is a dataset of General Practice prescribing data.  For each practice in England, the following information is available for for each medicine, dressing and appliance prescribed:\n",
    "* The total number of items prescribed and dispensed\n",
    "* The total net ingredient cost\n",
    "* The total actual cost\n",
    "* The total quantity\n",
    "\n",
    "The data covers NHS prescriptions written in England and dispensed in the community in the UK.\n",
    "\n",
    "Practices are identified only by their national code - an additional data file linked to the first by the practice code provides further detail in relation to the practice.\n",
    "\n",
    "Presentations are identified only by their BNF code, so an additional data file - linked to the first by the BNF code - provides the chemical name for that presentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Data Exploration\n",
    "Each monthly dataset has over 4 million rows.  I therefore chose to use OpenPrescribing, which provides an easy interface to access subsets of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Number of Prescriptions of a Specific Drug\n",
    "The graph below shows 4 separate time series for four given drugs.  This shows there is interdrug variation in prescription trends.  \n",
    "\n",
    "Some drugs such as simvastatin demonstrate a seamingly randomly fluctuating downwards trend.  Other such as amoxicillin, a commonly prescribed antibiotic, demonstrate more repetitive trends, indicative of the seasonality of the drug.  \n",
    "\n",
    "Losartan is an example of a drug that has little variation in prescribing behaviour over time.\n",
    "\n",
    "Salbutamol, which is a bronchodilator used in the treatment of astma, shows a more interesting time trend - it appears to have 4 peaks throughout the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from chart_studio.tools import set_config_file\n",
    "set_config_file(plotly_domain=\"https://plotly.com\", plotly_api_domain=\"https://api.plotly.com\")\n",
    "\n",
    "amox_overall= pd.read_csv('data/amoxicillin.csv')\n",
    "sim_overall = pd.read_csv('data/simvastatin.csv')\n",
    "los_overall = pd.read_csv('data/losartan.csv')\n",
    "sal_overall = pd.read_csv('data/salbutamol.csv')\n",
    "\n",
    "amox_overall['date'] =  pd.to_datetime(amox_overall['date'])\n",
    "los_overall['date'] =  pd.to_datetime(los_overall['date'])\n",
    "sim_overall['date'] =  pd.to_datetime(sim_overall['date'])\n",
    "sal_overall['date'] =  pd.to_datetime(sal_overall['date'])\n",
    "amox_overall = amox_overall[:-1]\n",
    "\n",
    "# Create traces\n",
    "trace0 = go.Scatter(\n",
    "    x = amox_overall['date'],\n",
    "    y = amox_overall['items'],\n",
    "    mode = 'lines+markers',\n",
    "    name = 'Amoxicillin'\n",
    ")\n",
    "trace1 = go.Scatter(\n",
    "    x = sim_overall['date'],\n",
    "    y = sim_overall['items'],\n",
    "    mode = 'lines+markers',\n",
    "    name = 'Simvastatin'\n",
    ")\n",
    "\n",
    "trace2 = go.Scatter(\n",
    "    x = los_overall['date'],\n",
    "    y = los_overall['items'],\n",
    "    mode = 'lines+markers',\n",
    "    name = 'Losartan'\n",
    ")\n",
    "\n",
    "trace3 = go.Scatter(\n",
    "    x = sal_overall['date'],\n",
    "    y = sal_overall['items'],\n",
    "    mode = 'lines+markers',\n",
    "    name = 'Salbutamol'\n",
    ")\n",
    "\n",
    "\n",
    "layout = dict(\n",
    "    title='Number of Prescriptions by Drug',\n",
    "    yaxis=dict(title = 'Number of Prescriptions'),\n",
    "    xaxis=dict(title = 'Year'),\n",
    "    \n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = [trace0, trace1, trace2, trace3]\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Number of Prescription by CCG\n",
    "All the practices in the UK are a member of one of 197 Clinical Commissioning Groups (CCGs).  You can look at the time trends of the number of prescriptions of a given drug by CCG - here I have selected 5 CCGs at random.  This demonstrates the consistent nature of the prescription patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "salbutamol_each = pd.read_csv('data/salbutamol_total.csv', index_col = 2)\n",
    "salbutamol_each['date'] =  pd.to_datetime(salbutamol_each['date'])\n",
    "practices = salbutamol_each.index.unique()\n",
    "\n",
    "seed = 5\n",
    "def get_data(dataframe, i):\n",
    "    x=i\n",
    "    times = []\n",
    "    while x > 0:\n",
    "        subset = dataframe[dataframe.index == practices[random.randint(3,197)]]\n",
    "        items = subset.y_items\n",
    "        times.append(items)\n",
    "        x -= 1\n",
    "    return times\n",
    "\n",
    "set_of_times = get_data(salbutamol_each, 5)\n",
    "\n",
    "# Create traces\n",
    "trace0 = go.Scatter(\n",
    "    x = amox_overall['date'],\n",
    "    y = set_of_times[0],\n",
    "    mode = 'lines+markers',\n",
    "    name = set_of_times[0].index[1]\n",
    ")\n",
    "trace1 = go.Scatter(\n",
    "    x = amox_overall['date'],\n",
    "    y = set_of_times[1],\n",
    "    mode = 'lines+markers',\n",
    "    name = set_of_times[1].index[1]\n",
    ")\n",
    "\n",
    "trace2 = go.Scatter(\n",
    "    x = amox_overall['date'],\n",
    "    y = set_of_times[2],\n",
    "    mode = 'lines+markers',\n",
    "    name = set_of_times[2].index[1]\n",
    ")\n",
    "\n",
    "trace3 = go.Scatter(\n",
    "    x = sal_overall['date'],\n",
    "    y = set_of_times[3],\n",
    "    mode = 'lines+markers',\n",
    "    name = set_of_times[3].index[1]\n",
    ")\n",
    "\n",
    "trace4 = go.Scatter(\n",
    "    x = sal_overall['date'],\n",
    "    y = set_of_times[4],\n",
    "    mode = 'lines+markers',\n",
    "    name = set_of_times[4].index[1]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "layout = dict(title = 'Number of Prescriptions of Salbutamol by Clinical Commissioning Groups (CCGs)',\n",
    "              xaxis = dict(title = 'Year', showgrid=True),\n",
    "              yaxis = dict(title = 'Number of Prescriptions', showgrid=True),\n",
    "              )\n",
    "\n",
    "data = [trace0, trace1, trace2, trace3, trace4]\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Normalising the Time Series\n",
    "\n",
    "It would be more interesting to see if the CCGs would cluster based on the prescription trends instead of simply those prescribing more.  To look at this, I will need to scale the prescriptions of each CCG proportionally.\n",
    "\n",
    "\n",
    "Need to take the mean nuber of prescriptions for each CCG and subtract the number of prescriptions for each time point from this mean.  Then take this value and divide by the mean.\n",
    "\n",
    "Use the z-normalisation, first mentioned by Goldin & Kanellakis.  This ensures, that all elements of the input vector are transformed into the output vector whose mean is approximately 0 while the standard deviation is in a range close to 1.\n",
    "\n",
    "First, the time series mean is subtracted from original values, and second, the difference is divided by the standard deviation value. According to most of the recent work concerned with time series structural pattern mining, z-normalization is an essential preprocessing step which allows a mining algorithm to focus on the structural similarities/dissimilarities rather than on the amplitude-driven ones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Normalised Salbutamol by CCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mean_value = []\n",
    "std_value = []\n",
    "\n",
    "for time_series in set_of_times:\n",
    "    av = np.mean(time_series)\n",
    "    mean_value.append(av)\n",
    "    std = np.std(time_series)\n",
    "    std_value.append(std)\n",
    "\n",
    "len(mean_value)\n",
    "\n",
    "# Need to subtract mean from each value in each time series in timeSeries and divide by the sd.\n",
    "mean_subtracted_series = []\n",
    "x = 0\n",
    "\n",
    "\n",
    "\n",
    "for time_series in set_of_times:\n",
    "    timings = []\n",
    "    average = mean_value[x]\n",
    "    std = std_value[x]\n",
    "    for time in time_series:\n",
    "        subtracted = (time - average)/std\n",
    "        timings.append(subtracted)\n",
    "    x += 1\n",
    "    mean_subtracted_series.append(timings)\n",
    "\n",
    "\n",
    "# Create traces\n",
    "trace0 = go.Scatter(\n",
    "    x = amox_overall['date'],\n",
    "    y = mean_subtracted_series[0],\n",
    "    mode = 'lines+markers',\n",
    "    name = set_of_times[0].index[1]\n",
    ")\n",
    "trace1 = go.Scatter(\n",
    "    x = sim_overall['date'],\n",
    "    y = mean_subtracted_series[1],\n",
    "    mode = 'lines+markers',\n",
    "    name = set_of_times[1].index[1]\n",
    ")\n",
    "\n",
    "trace2 = go.Scatter(\n",
    "    x = los_overall['date'],\n",
    "    y = mean_subtracted_series[2],\n",
    "    mode = 'lines+markers',\n",
    "    name = set_of_times[2].index[1]\n",
    ")\n",
    "\n",
    "trace3 = go.Scatter(\n",
    "    x = sal_overall['date'],\n",
    "    y = mean_subtracted_series[3],\n",
    "    mode = 'lines+markers',\n",
    "    name = set_of_times[3].index[1]\n",
    ")\n",
    "\n",
    "\n",
    "trace4 = go.Scatter(\n",
    "    x = sal_overall['date'],\n",
    "    y = mean_subtracted_series[4],\n",
    "    mode = 'lines+markers',\n",
    "    name = set_of_times[4].index[1]\n",
    ")\n",
    "\n",
    "layout = dict(\n",
    "    title='Normalised Prescriptions by CCG',\n",
    "    yaxis=dict(title = 'Normalised Number of Prescriptions'),\n",
    "    xaxis=dict(title = 'Year')\n",
    ")\n",
    "\n",
    "\n",
    "data = [trace0, trace1, trace2, trace3, trace4]\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Time Series Smoothing\n",
    "\n",
    "Time series smoothing will remove any \"noise\" and give a better sense of trend by which clustering will better.\n",
    "\n",
    "### Moving Average\n",
    "\n",
    "This method, for every time point takes the average of the surrounding time points.  The amount of surrounding points accounted for is known as the window size.  Here it is set to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "mean_subtracted_series = []\n",
    "x = 0\n",
    "\n",
    "\n",
    "def moving_average(a, n=9) :\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n\n",
    "\n",
    "\n",
    "for time_series in set_of_times:\n",
    "    timings = []\n",
    "    average = mean_value[x]\n",
    "    std = std_value[x]\n",
    "    for time in time_series:\n",
    "        subtracted = (time - average)/std\n",
    "        timings.append(subtracted)\n",
    "    x += 1\n",
    "    a = moving_average(timings)\n",
    "    mean_subtracted_series.append(a)\n",
    "\n",
    "\n",
    "# Create traces\n",
    "trace0 = go.Scatter(\n",
    "    x = amox_overall['date'],\n",
    "    y = mean_subtracted_series[0],\n",
    "    mode = 'lines+markers',\n",
    "    name = set_of_times[0].index[1]\n",
    ")\n",
    "trace1 = go.Scatter(\n",
    "    x = sim_overall['date'],\n",
    "    y = mean_subtracted_series[1],\n",
    "    mode = 'lines+markers',\n",
    "    name = set_of_times[1].index[1]\n",
    ")\n",
    "\n",
    "trace2 = go.Scatter(\n",
    "    x = los_overall['date'],\n",
    "    y = mean_subtracted_series[2],\n",
    "    mode = 'lines+markers',\n",
    "    name = set_of_times[2].index[1]\n",
    ")\n",
    "\n",
    "trace3 = go.Scatter(\n",
    "    x = sal_overall['date'],\n",
    "    y = mean_subtracted_series[3],\n",
    "    mode = 'lines+markers',\n",
    "    name = set_of_times[3].index[1]\n",
    ")\n",
    "\n",
    "\n",
    "trace4 = go.Scatter(\n",
    "    x = sal_overall['date'],\n",
    "    y = mean_subtracted_series[4],\n",
    "    mode = 'lines+markers',\n",
    "    name = set_of_times[4].index[1]\n",
    ")\n",
    "\n",
    "layout = dict(\n",
    "    title='Moving Average',\n",
    "    yaxis=dict(title = 'Normalised Number of Prescriptions'),\n",
    "    xaxis=dict(title = 'Year')\n",
    ")\n",
    "\n",
    "\n",
    "data = [trace0, trace1, trace2, trace3, trace4]\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Savitzky–Golay Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mean_subtracted_series = []\n",
    "x = 0\n",
    "\n",
    "\n",
    "\n",
    "for time_series in set_of_times:\n",
    "    timings = []\n",
    "    average = mean_value[x]\n",
    "    std = std_value[x]\n",
    "    for time in time_series:\n",
    "        subtracted = (time - average)/std\n",
    "        timings.append(subtracted)\n",
    "    x += 1\n",
    "    a = sc.savgol_filter(timings, 11, 2)\n",
    "    mean_subtracted_series.append(a)\n",
    "\n",
    "# Create traces\n",
    "trace0 = go.Scatter(\n",
    "    x = amox_overall['date'],\n",
    "    y = mean_subtracted_series[0],\n",
    "    mode = 'lines+markers',\n",
    "    name = set_of_times[0].index[1]\n",
    ")\n",
    "trace1 = go.Scatter(\n",
    "    x = sim_overall['date'],\n",
    "    y = mean_subtracted_series[1],\n",
    "    mode = 'lines+markers',\n",
    "    name = set_of_times[1].index[1]\n",
    ")\n",
    "\n",
    "trace2 = go.Scatter(\n",
    "    x = los_overall['date'],\n",
    "    y = mean_subtracted_series[2],\n",
    "    mode = 'lines+markers',\n",
    "    name = set_of_times[2].index[1]\n",
    ")\n",
    "\n",
    "trace3 = go.Scatter(\n",
    "    x = sal_overall['date'],\n",
    "    y = mean_subtracted_series[3],\n",
    "    mode = 'lines+markers',\n",
    "    name = set_of_times[3].index[1]\n",
    ")\n",
    "\n",
    "\n",
    "trace4 = go.Scatter(\n",
    "    x = sal_overall['date'],\n",
    "    y = mean_subtracted_series[4],\n",
    "    mode = 'lines+markers',\n",
    "    name = set_of_times[4].index[1]\n",
    ")\n",
    "\n",
    "layout = dict(\n",
    "    title='Savgol Filtering',\n",
    "    yaxis=dict(title = 'Scaled Number of Prescriptions'),\n",
    "    xaxis=dict(title = 'Year',\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "data = [trace0, trace1, trace2, trace3, trace4]\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Unsupervised Approach - Hierarchical Clustering\n",
    "The below shows a hierarchical clustering of salbutamol prescriptions.  The distance metric used is Euclidean distance.  \n",
    "\n",
    "### Clustering Salbutamol by CCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "methods = ['single', 'complete', 'average', 'weighted', 'centroid', 'median', 'ward']\n",
    "\n",
    "metrics = ['euclidean', 'cityblock', 'minkowski', 'chebyshev', 'correlation', 'cosine' , 'matching']\n",
    "\n",
    "salbutamol_each = pd.read_csv('data/salbutamol_total.csv', index_col = 2)\n",
    "salbutamol_each['date'] =  pd.to_datetime(salbutamol_each['date'])\n",
    "practices = salbutamol_each.index.unique()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_data(dataframe):\n",
    "    times = []\n",
    "    z = 0\n",
    "    for practice in practices:\n",
    "        subset = dataframe[dataframe.index == practice]\n",
    "        items = subset.y_items\n",
    "        times.append(items.values)\n",
    "        z += 1\n",
    "        \n",
    "    return times\n",
    "\n",
    "a = (get_data(salbutamol_each))\n",
    "\n",
    "\n",
    "mean_value = []\n",
    "std_value = []\n",
    "\n",
    "for time_series in a:\n",
    "    av = np.mean(time_series)\n",
    "    mean_value.append(av)\n",
    "    std = np.std(time_series)\n",
    "    std_value.append(std)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y=2\n",
    "\n",
    "mean_subtracted_series = []\n",
    "\n",
    "\n",
    "\n",
    "for time_series in a[2:]:\n",
    "    timings = []\n",
    "    average = mean_value[y]\n",
    "    std = std_value[y]\n",
    "    for time in time_series:\n",
    "        subtracted = (time - average)/std\n",
    "        timings.append(subtracted)\n",
    "    a = sc.savgol_filter(timings, 11, 2)\n",
    "    mean_subtracted_series.append(a)\n",
    "    y += 1\n",
    "\n",
    "\n",
    "Z = hac.linkage(mean_subtracted_series, method='average', metric='euclidean')\n",
    "\n",
    "# Plot dendogram\n",
    "plt.figure(figsize=(25, 10))\n",
    "plt.title('Hierarchical Clustering Dendrogram - Salbutamol Prescriptions')\n",
    "plt.xlabel('CCG')\n",
    "plt.ylabel('Distance')\n",
    "hac.dendrogram(\n",
    "    Z,\n",
    "    labels=practices[2:],\n",
    "    leaf_rotation=90.,  # rotates the x axis labels\n",
    "    leaf_font_size=8.,)  # font size for the x axis labels\n",
    "#plt.savefig('/Users/Louis/Desktop/foo.png')\n",
    "plt.show() \n",
    "\n",
    "c, coph_dists = hac.cophenet(Z, pdist(mean_subtracted_series))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "scores = {}\n",
    "while x < 49:\n",
    "    try:\n",
    "        for i in methods:\n",
    "            for t in metrics:\n",
    "                Z = hac.linkage(mean_subtracted_series, method=i, metric=t)\n",
    "                c, coph_dists = hac.cophenet(Z, pdist(mean_subtracted_series))\n",
    "                x +=1\n",
    "                scores[i + ' ' + t] = round(c, 3)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "print(scores)\n",
    "    \n",
    "print(\"Average euclidean is good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#Clustered together\n",
    "print(f\"The index of NHS NEWHAM CCG is {practices.get_loc('NHS NEWHAM CCG')}\")\n",
    "print(f\"The index of NHS EAST LANCASHIRE CCG is {practices.get_loc('NHS EAST LANCASHIRE CCG')}\")\n",
    "\n",
    "#Clustered close\n",
    "\n",
    "print(f\"The index of NHS VALE ROYAL CCG is {practices.get_loc('NHS VALE ROYAL CCG')}\")\n",
    "print(f\"The index of NHS HULL CCG is {practices.get_loc('NHS HULL CCG')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create traces\n",
    "trace0 = go.Scatter(\n",
    "    x = amox_overall['date'],\n",
    "    y = mean_subtracted_series[127],\n",
    "    mode = 'lines+markers',\n",
    "    name = practices[127]\n",
    ")\n",
    "trace1 = go.Scatter(\n",
    "    x = sim_overall['date'],\n",
    "    y = mean_subtracted_series[182],\n",
    "    mode = 'lines+markers',\n",
    "    name = practices[182]\n",
    ")\n",
    "\n",
    "\n",
    "trace2 = go.Scatter(\n",
    "    x = sim_overall['date'],\n",
    "    y = mean_subtracted_series[21],\n",
    "    mode = 'lines+markers',\n",
    "    name = practices[21]\n",
    ")\n",
    "\n",
    "trace3 = go.Scatter(\n",
    "    x = sim_overall['date'],\n",
    "    y = mean_subtracted_series[170],\n",
    "    mode = 'lines+markers',\n",
    "    name = practices[170]\n",
    ")\n",
    "\n",
    "layout = dict(\n",
    "    title='Number of Prescriptions per Drug',\n",
    "    yaxis=dict(title = 'Number of Prescriptions per Drug'),\n",
    "    xaxis=dict(title = 'Year')\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "data = [trace0, trace1, trace2, trace3]\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "k = 3\n",
    "\n",
    "def print_clusters(timeSeries, Z, k, plot=False):\n",
    "    # k Number of clusters I'd like to extract\n",
    "    results = fcluster(Z, k, criterion='maxclust')\n",
    "\n",
    "    # check the results\n",
    "    s = pd.Series(results)\n",
    "    clusters = s.unique()\n",
    "\n",
    "    for c in clusters:\n",
    "        cluster_indeces = s[s==c].index\n",
    "        print(\"Cluster %d number of entries %d\" % (c, len(cluster_indeces)))\n",
    "        if plot:\n",
    "            timeSeries.T.iloc[:,cluster_indeces].plot()\n",
    "            plt.show()\n",
    "\n",
    "# print_clusters(mean_subtracted_series, Z, k, plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Cophenetic Correlation Coefficient\n",
    "The cophenetic correlation for a cluster tree is defined as the linear correlation coefficient between the cophenetic distances obtained from the tree, and the original distances (or dissimilarities) used to construct the tree. Thus, it is a measure of how faithfully the tree represents the dissimilarities among observations.\n",
    "\n",
    "The cophenetic distance between two observations is represented in a dendrogram by the height of the link at which those two observations are first joined. That height is the distance between the two subclusters that are merged by that link.\n",
    "\n",
    "The output value, c, is the cophenetic correlation coefficient. The magnitude of this value should be very close to 1 for a high-quality solution. This measure can be used to compare alternative cluster solutions obtained using different algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "x = 0\n",
    "scores =[]\n",
    "while x <49:\n",
    "    try:\n",
    "        for i in methods:\n",
    "            for t in metrics:\n",
    "                Z = hac.linkage(mean_subtracted_series, method=i, metric=t)\n",
    "                c, coph_dists = hac.cophenet(Z, pdist(mean_subtracted_series))\n",
    "                x +=1\n",
    "                scores.append(c)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "\n",
    "print(f\"Best combination is average and Euclidean Distance, with CCC of {max(scores)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "Z = hac.linkage(mean_subtracted_series, method='average', metric='euclidean')\n",
    "plt.figure(figsize=(25, 10))\n",
    "plt.title('Hierarchical Clustering Dendrogram - Salbutamol Prescriptions')\n",
    "plt.xlabel('CCG')\n",
    "plt.ylabel('Distance')\n",
    "hac.dendrogram(\n",
    "    Z,\n",
    "    labels=practices[2:],\n",
    "    leaf_rotation=90.,  # rotates the x axis labels\n",
    "    leaf_font_size=8.,)  # font size for the x axis labels\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print_clusters(mean_subtracted_series, Z, 3, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "k=3\n",
    "b = fcluster(Z, k, criterion='maxclust')\n",
    "b = b.tolist()\n",
    "\n",
    "\n",
    "index_cluster_one = []\n",
    "index_cluster_three = []\n",
    "index_cluster_two = []\n",
    "\n",
    "for c, value in enumerate(b, 0):\n",
    "    if value == 1:\n",
    "        index_cluster_one.append(c)\n",
    "    elif value ==2:\n",
    "        index_cluster_two.append(c)\n",
    "    else:\n",
    "        index_cluster_three.append(c)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "cluster_one_series = []\n",
    "for i in index_cluster_one:\n",
    "    cluster_one_series.append(mean_subtracted_series[i])\n",
    "\n",
    "mean_cluster_one =  np.mean(cluster_one_series, axis=0)\n",
    "std_cluster_one = np.std(cluster_one_series, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cluster_two_series = []\n",
    "for i in index_cluster_two:\n",
    "    cluster_two_series.append(mean_subtracted_series[i])\n",
    "\n",
    "mean_cluster_two =  np.mean(cluster_two_series, axis=0)\n",
    "std_cluster_two = np.std(cluster_two_series, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cluster_three_series = []\n",
    "for i in index_cluster_three:\n",
    "    cluster_three_series.append(mean_subtracted_series[i])\n",
    "\n",
    "mean_cluster_three =  np.mean(cluster_three_series, axis=0)\n",
    "std_cluster_three = np.std(cluster_three_series, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "upper_bound1 = go.Scatter(\n",
    "    name='Upper Bound',\n",
    "    x=sim_overall['date'],\n",
    "    y=mean_cluster_one+std_cluster_one,\n",
    "    mode='lines',\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(68, 68, 68, 0.3)',\n",
    "    fill='tonexty')\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    name='Measurement',\n",
    "    x=sim_overall['date'],\n",
    "    y=mean_cluster_one,\n",
    "    mode='lines',\n",
    "    line=dict(color='rgb(10, 160, 160)'),\n",
    "    fillcolor='rgba(68, 68, 68, 0.3)',\n",
    "    fill='tonexty')\n",
    "\n",
    "lower_bound1 = go.Scatter(\n",
    "    name='Lower Bound',\n",
    "    x=sim_overall['date'],\n",
    "    y=mean_cluster_one-std_cluster_one,\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    mode='lines')\n",
    "\n",
    "\n",
    "upper_bound2 = go.Scatter(\n",
    "    name='Upper Bound',\n",
    "    x=sim_overall['date'],\n",
    "    y=mean_cluster_two+std_cluster_two,\n",
    "    mode='lines',\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(100, 100, 100, 0.8)',\n",
    "    fill='tonexty')\n",
    "\n",
    "trace2 = go.Scatter(\n",
    "    name='Measurement',\n",
    "    x=sim_overall['date'],\n",
    "    y=mean_cluster_two,\n",
    "    mode='lines',\n",
    "    line=dict(color='rgb(31, 119, 180)'),\n",
    "    fillcolor='rgba(100, 100, 100, 0.8)',\n",
    "    fill='tonexty')\n",
    "\n",
    "lower_bound2 = go.Scatter(\n",
    "    name='Lower Bound',\n",
    "    x=sim_overall['date'],\n",
    "    y=mean_cluster_two-std_cluster_two,\n",
    "    marker=dict(color=\"#400\"),\n",
    "    line=dict(width=0),\n",
    "    mode='lines')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "upper_bound3 = go.Scatter(\n",
    "    name='Upper Bound',\n",
    "    x=sim_overall['date'],\n",
    "    y=mean_cluster_three+std_cluster_three,\n",
    "    mode='lines',\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(30, 30, 30, 0.6)',\n",
    "    fill='tonexty')\n",
    "\n",
    "trace3 = go.Scatter(\n",
    "    name='Measurement',\n",
    "    x=sim_overall['date'],\n",
    "    y=mean_cluster_three,\n",
    "    mode='lines',\n",
    "    line=dict(color='rgb(50, 80, 180)'),\n",
    "    fillcolor='rgba(30, 30, 30, 0.6)',\n",
    "    fill='tonexty')\n",
    "\n",
    "lower_bound3 = go.Scatter(\n",
    "    name='Lower Bound',\n",
    "    x=sim_overall['date'],\n",
    "    y=mean_cluster_three-std_cluster_three,\n",
    "    marker=dict(color=\"#500\"),\n",
    "    line=dict(width=0),\n",
    "    mode='lines')\n",
    "\n",
    "\n",
    "\n",
    "# Trace order can be important\n",
    "# with continuous error bars\n",
    "data = [lower_bound1, trace1, upper_bound1, lower_bound2, trace2, upper_bound2, lower_bound3, trace3, upper_bound3]\n",
    "layout = go.Layout(\n",
    "    yaxis=dict(title='Normalised Number of Prescriptions'),\n",
    "    title='Cluster Comparison - Salbutamol',\n",
    "    showlegend = False)\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='pandas-continuous-error-bars')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Normalised Clustering of Tramadol\n",
    "The below shows a clustering of Tramadol prescriptions for each CCG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tramadol_each= pd.read_csv('data/tramadol.csv', index_col=2)\n",
    "tramadol_each['date'] =  pd.to_datetime(tramadol_each['date'])\n",
    "practices = tramadol_each.index.unique()\n",
    "\n",
    "a = (get_data(tramadol_each))\n",
    "\n",
    "\n",
    "mean_value = []\n",
    "std_value = []\n",
    "\n",
    "for time_series in a:\n",
    "    av = np.mean(time_series)\n",
    "    mean_value.append(av)\n",
    "    std = np.std(time_series)\n",
    "    std_value.append(std)\n",
    "\n",
    "\n",
    "y=2\n",
    "\n",
    "mean_subtracted_series = []\n",
    "\n",
    "\n",
    "\n",
    "for time_series in a[2:]:\n",
    "    timings = []\n",
    "    average = mean_value[y]\n",
    "    std = std_value[y]\n",
    "    for time in time_series:\n",
    "        subtracted = (time - average)/std\n",
    "        timings.append(subtracted)\n",
    "    a = sc.savgol_filter(timings, 11, 2)\n",
    "    mean_subtracted_series.append(a)\n",
    "    y += 1\n",
    "\n",
    "\n",
    "  \n",
    "Z = hac.linkage(mean_subtracted_series, method='average', metric='euclidean')\n",
    "\n",
    "# Plot dendogram\n",
    "plt.figure(figsize=(25, 10))\n",
    "plt.title('Hierarchical Clustering Dendrogram - Salbutamol Prescriptions')\n",
    "plt.xlabel('CCG')\n",
    "plt.ylabel('Distance')\n",
    "hac.dendrogram(\n",
    "    Z,\n",
    "    labels=practices[2:],\n",
    "    leaf_rotation=90.,  # rotates the x axis labels\n",
    "    leaf_font_size=8.,)  # font size for the x axis labels\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "Z = hac.linkage(mean_subtracted_series, method='average', metric='euclidean')\n",
    "\n",
    "\n",
    "k=3\n",
    "b = fcluster(Z, k, criterion='maxclust')\n",
    "b = b.tolist()\n",
    "\n",
    "\n",
    "index_cluster_one = []\n",
    "index_cluster_three = []\n",
    "index_cluster_two = []\n",
    "index_cluster_four = []\n",
    "\n",
    "for c, value in enumerate(b, 0):\n",
    "    if value == 1:\n",
    "        index_cluster_one.append(c)\n",
    "    elif value ==2:\n",
    "        index_cluster_two.append(c)\n",
    "    elif value ==3:\n",
    "        index_cluster_three.append(c)\n",
    "    else:\n",
    "        index_cluster_four.append(c)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "print(len(index_cluster_three))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "cluster_one_series = []\n",
    "for i in index_cluster_one:\n",
    "    cluster_one_series.append(mean_subtracted_series[i])\n",
    "\n",
    "mean_cluster_one =  np.mean(cluster_one_series, axis=0)\n",
    "std_cluster_one = np.std(cluster_one_series, axis=0)\n",
    "\n",
    "\n",
    "cluster_two_series = []\n",
    "for i in index_cluster_two:\n",
    "    cluster_two_series.append(mean_subtracted_series[i])\n",
    "\n",
    "mean_cluster_two =  np.mean(cluster_two_series, axis=0)\n",
    "std_cluster_two = np.std(cluster_two_series, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cluster_three_series = []\n",
    "for i in index_cluster_three:\n",
    "    cluster_three_series.append(mean_subtracted_series[i])\n",
    "\n",
    "mean_cluster_three =  np.mean(cluster_three_series, axis=0)\n",
    "std_cluster_three = np.std(cluster_three_series, axis=0)\n",
    "\n",
    "\n",
    "cluster_four_series = []\n",
    "for i in index_cluster_four:\n",
    "    cluster_four_series.append(mean_subtracted_series[i])\n",
    "\n",
    "mean_cluster_four =  np.mean(cluster_four_series, axis=0)\n",
    "std_cluster_four = np.std(cluster_four_series, axis=0)\n",
    "\n",
    "\n",
    "upper_bound1 = go.Scatter(\n",
    "    name='Upper Bound',\n",
    "    x=sim_overall['date'],\n",
    "    y=mean_cluster_one+std_cluster_one,\n",
    "    mode='lines',\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(68, 68, 68, 0.3)',\n",
    "    fill='tonexty')\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    name='Measurement',\n",
    "    x=sim_overall['date'],\n",
    "    y=mean_cluster_one,\n",
    "    mode='lines',\n",
    "    line=dict(color='rgb(10, 160, 160)'),\n",
    "    fillcolor='rgba(68, 68, 68, 0.3)',\n",
    "    fill='tonexty')\n",
    "\n",
    "lower_bound1 = go.Scatter(\n",
    "    name='Lower Bound',\n",
    "    x=sim_overall['date'],\n",
    "    y=mean_cluster_one-std_cluster_one,\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    mode='lines')\n",
    "\n",
    "\n",
    "upper_bound2 = go.Scatter(\n",
    "    name='Upper Bound',\n",
    "    x=sim_overall['date'],\n",
    "    y=mean_cluster_two+std_cluster_two,\n",
    "    mode='lines',\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(100, 100, 100, 0.8)',\n",
    "    fill='tonexty')\n",
    "\n",
    "trace2 = go.Scatter(\n",
    "    name='Measurement',\n",
    "    x=sim_overall['date'],\n",
    "    y=mean_cluster_two,\n",
    "    mode='lines',\n",
    "    line=dict(color='rgb(31, 119, 180)'),\n",
    "    fillcolor='rgba(100, 100, 100, 0.8)',\n",
    "    fill='tonexty')\n",
    "\n",
    "lower_bound2 = go.Scatter(\n",
    "    name='Lower Bound',\n",
    "    x=sim_overall['date'],\n",
    "    y=mean_cluster_two-std_cluster_two,\n",
    "    marker=dict(color=\"#400\"),\n",
    "    line=dict(width=0),\n",
    "    mode='lines')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "upper_bound3 = go.Scatter(\n",
    "    name='Upper Bound',\n",
    "    x=sim_overall['date'],\n",
    "    y=mean_cluster_three+std_cluster_three,\n",
    "    mode='lines',\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(30, 30, 30, 0.6)',\n",
    "    fill='tonexty')\n",
    "\n",
    "trace3 = go.Scatter(\n",
    "    name='Measurement',\n",
    "    x=sim_overall['date'],\n",
    "    y=mean_cluster_three,\n",
    "    mode='lines',\n",
    "    line=dict(color='rgb(50, 80, 180)'),\n",
    "    fillcolor='rgba(30, 30, 30, 0.6)',\n",
    "    fill='tonexty')\n",
    "\n",
    "# lower_bound3 = go.Scatter(\n",
    "#     name='Lower Bound',\n",
    "#     x=sim_overall['date'],\n",
    "#     y=mean_cluster_three-std_cluster_three,\n",
    "#     marker=dict(color=\"#500\"),\n",
    "#     line=dict(width=0),\n",
    "#     mode='lines')\n",
    "\n",
    "\n",
    "\n",
    "# upper_bound4 = go.Scatter(\n",
    "#     name='Upper Bound',\n",
    "#     x=sim_overall['date'],\n",
    "#     y=mean_cluster_four+std_cluster_four,\n",
    "#     mode='lines',\n",
    "#     marker=dict(color=\"#444\"),\n",
    "#     line=dict(width=0),\n",
    "#     fillcolor='rgba(30, 30, 30, 0.6)',\n",
    "#     fill='tonexty')\n",
    "\n",
    "# trace4 = go.Scatter(\n",
    "#     name='Measurement',\n",
    "#     x=sim_overall['date'],\n",
    "#     y=mean_cluster_four,\n",
    "#     mode='lines',\n",
    "#     line=dict(color='red'),\n",
    "#     fillcolor='rgba(30, 30, 30, 0.6)',\n",
    "#     fill='tonexty')\n",
    "\n",
    "# lower_bound4 = go.Scatter(\n",
    "#     name='Lower Bound',\n",
    "#     x=sim_overall['date'],\n",
    "#     y=mean_cluster_four-std_cluster_four,\n",
    "#     marker=dict(color=\"#500\"),\n",
    "#     line=dict(width=0),\n",
    "#     mode='lines')\n",
    "\n",
    "# Trace order can be important\n",
    "# with continuous error bars\n",
    "data = [lower_bound1, trace1, upper_bound1, lower_bound2, trace2, upper_bound2, lower_bound3, trace3, upper_bound3]\n",
    "layout = go.Layout(\n",
    "    yaxis=dict(title='Normalised Number of Prescriptions'),\n",
    "    title='Cluster Comparison - Tramadol',\n",
    "    showlegend = False)\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='pandas-continuous-error-bars')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "You can see some delineation between the clusters.\n",
    "### Moving from CCG to Practice Level\n",
    "The above clustering was performed on 195 CCGs.  Within these CCGs there are > 10, 000 practices.  Getting data for individual practices in bulk isn't available through OpenPrescribing.  I will need to download the complete dataset covering all drugs and all practices.  I will then need to select from this a single drug (Tramadol) and then divide this data by practice and order according to the time.\n",
    "\n",
    "#### Getting Practice Level Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "FINAL = pd.read_csv('data/tramadol.csv')\n",
    "practices = FINAL.PRACTICE.unique()\n",
    "print(f\"The final shape of the dataframe of every practices tramadol prescriptions is {FINAL.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "files = os.listdir(\"data/tramadol_data\")\n",
    "example_pd = pd.read_csv(os.path.join(\"data/tramadol_data\", files[1]))\n",
    "\n",
    "print(f\"This can be divided into {len(files)} practices, each with {example_pd.shape[0]} time points\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Clustering at Individual Practice Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#For loop opening each csv and adding to a list.\n",
    "\n",
    "\n",
    "timeSeries = []\n",
    "for file in os.listdir(\"data/tramadol_data\"):\n",
    "    data = pd.read_csv(os.path.join(\"data/tramadol_data\", file))\n",
    "    items = data['ITEMS__'].tolist()\n",
    "    timeSeries.append(items)\n",
    "\n",
    "dates = pd.read_csv(\"data/tramadol_data/M84067.csv\")\n",
    "dates = dates.PERIOD\n",
    "    \n",
    "not_full_time = []\n",
    "\n",
    "for series in timeSeries:\n",
    "    if len(series) == 96:\n",
    "        not_full_time.append(timeSeries.index(series))\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "print(f\"There are a total of {len(timeSeries)} practices\")\n",
    "print(f\"{len(timeSeries) - len(not_full_time)} of these do not have the full 96 time points\")\n",
    "    \n",
    "\n",
    "mean_value = []\n",
    "std_value = []\n",
    "\n",
    "for time_series in timeSeries:\n",
    "    av = np.mean(time_series)\n",
    "    mean_value.append(av)\n",
    "    std = np.std(time_series)\n",
    "    std_value.append(std)\n",
    "\n",
    "\n",
    "only_ninety_six = []\n",
    "ninety_practices = []\n",
    "\n",
    "for counter, value in enumerate(timeSeries, start=0):\n",
    "    if len(value) ==96:\n",
    "        only_ninety_six.append(value)\n",
    "        ninety_practices.append(practices[counter])\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "individual_series = []\n",
    "x = 0\n",
    "for time_series in only_ninety_six:\n",
    "    timings = []\n",
    "    average = mean_value[not_full_time[x]]\n",
    "    std = std_value[not_full_time[x]]\n",
    "    for time in time_series:\n",
    "        subtracted = (time - average)/std\n",
    "        timings.append(subtracted)\n",
    "    \n",
    "    a = sc.savgol_filter(timings, 11, 2)\n",
    "    individual_series.append(a)   \n",
    "    x += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dates = pd.to_datetime(dates, format='%Y%m')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "methods = ['single', 'complete', 'average', 'weighted', 'centroid', 'median', 'ward']\n",
    "\n",
    "metrics = ['euclidean', 'cityblock', 'minkowski', 'chebyshev', 'correlation', 'cosine' , 'matching']\n",
    "\n",
    "x = 0\n",
    "scores =[]\n",
    "while x < 73:\n",
    "    try:\n",
    "        for i in methods:\n",
    "            for t in metrics:\n",
    "                Z = hac.linkage(individual_series, method=i, metric=t)\n",
    "                c, coph_dists = hac.cophenet(Z, pdist(individual_series))\n",
    "                x +=1\n",
    "                scores.append(c)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "print(max(scores))\n",
    "print(scores.index(max(scores)))\n",
    "print(\"Best combination is Average ane Euclidean Distance, with CCC of 0.627\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.index(0.6199345484333891)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "print(max(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Best is centroid and euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "scores.index(0.7879663965126165)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "linked = hac.linkage(individual_series, method='average', metric='cityblock')\n",
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "plt.title('Hierarchical Clustering Dendrogram - Tramadol Prescriptions')\n",
    "plt.xlabel('CCG')\n",
    "plt.ylabel('Distance')\n",
    "hac.dendrogram(\n",
    "    linked,\n",
    "    leaf_rotation=90.,  # rotates the x axis labels\n",
    "    leaf_font_size=8.,  # font size for the x axis labels\n",
    "labels = ninety_practices)\n",
    "plt.show()\n",
    "\n",
    "print(f\"This shows a clustering of {len(individual_series) - len(not_full_time)} practices.\")\n",
    "\n",
    "\n",
    "c, coph_dists = hac.cophenet(linked, pdist(individual_series))\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_clusters(individual_series, linked, 5, plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deciding on the Best K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.metrics as met\n",
    "\n",
    "\n",
    "CH_SCORES = []\n",
    "u = 0\n",
    "for k in range(2, 30):\n",
    "    linked = hac.linkage(individual_series, method='average', metric='cityblock')\n",
    "    labels = fcluster(linked, k, criterion='maxclust')\n",
    "    CH_score = met.calinski_harabaz_score(individual_series, labels)\n",
    "    CH_SCORES.append(CH_score)\n",
    "    print(f'Complete {u}')\n",
    "    u +=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The best CH score is  achieved with {CH_SCORES.index(max(CH_SCORES)) + 2} clusters.  The score with this number of clusters is {max(CH_SCORES)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CH_SCORES.index(1465.0316998573974)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "k=3\n",
    "b = fcluster(linked, k, criterion='maxclust')\n",
    "b = b.tolist()\n",
    "\n",
    "index_cluster_one = []\n",
    "index_cluster_two = []\n",
    "index_cluster_three = []\n",
    "index_cluster_four = []\n",
    "index_cluster_five = []\n",
    "\n",
    "for c, value in enumerate(b, 0):\n",
    "    \n",
    "    if value == 1:\n",
    "        index_cluster_one.append(c)\n",
    "    elif value ==2:\n",
    "        index_cluster_two.append(c)\n",
    "    elif value ==3:\n",
    "        index_cluster_three.append(c)\n",
    "    elif value ==4:\n",
    "        index_cluster_four.append(c)\n",
    "    else:\n",
    "        index_cluster_five.append(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_clusters(individual_series, linked, 3, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_one_series = []\n",
    "for i in index_cluster_one:\n",
    "    cluster_one_series.append(individual_series[i])\n",
    "\n",
    "mean_cluster_one =  np.mean(cluster_one_series, axis=0)\n",
    "std_cluster_one = np.std(cluster_one_series, axis=0)\n",
    "\n",
    "\n",
    "cluster_two_series = []\n",
    "for i in index_cluster_two:\n",
    "    cluster_two_series.append(individual_series[i])\n",
    "\n",
    "mean_cluster_two =  np.mean(cluster_two_series, axis=0)\n",
    "std_cluster_two = np.std(cluster_two_series, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "cluster_three_series = []\n",
    "for i in index_cluster_three:\n",
    "    cluster_three_series.append(individual_series[i])\n",
    "\n",
    "mean_cluster_three =  np.mean(cluster_three_series, axis=0)\n",
    "std_cluster_three = np.std(cluster_three_series, axis=0)\n",
    "\n",
    "\n",
    "upper_bound1 = go.Scatter(\n",
    "    opacity=0.8,\n",
    "    name='Upper Bound Cluster 1',\n",
    "    x=dates,\n",
    "    y=mean_cluster_one+std_cluster_one,\n",
    "    mode='lines',\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(10,150,65,0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    opacity=0.8,\n",
    "    name='Mean Cluster 1',\n",
    "    x=dates,\n",
    "    y=mean_cluster_one,\n",
    "    mode='lines',\n",
    "    line=dict(color='rgb(0, 255, 93)'),\n",
    "    fillcolor='rgba(10,150,65,0.5)',\n",
    "    fill='tonexty' \n",
    "   )\n",
    "\n",
    "lower_bound1 = go.Scatter(\n",
    "    opacity=0.8,\n",
    "    name='Lower Bound Cluster 1',\n",
    "    x=dates,\n",
    "    y=mean_cluster_one-std_cluster_one,\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    mode='lines')\n",
    "\n",
    "\n",
    "upper_bound2 = go.Scatter(\n",
    "    name='Upper Bound Cluster 2',\n",
    "    x=dates,\n",
    "    y=mean_cluster_two+std_cluster_two,\n",
    "    mode='lines',\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(29,96, 141, 0.5)',\n",
    "    fill='tonexty',\n",
    "    opacity = 0.8)\n",
    "\n",
    "trace2 = go.Scatter(\n",
    "    name='Mean Cluster 2',\n",
    "    x=dates,\n",
    "    y=mean_cluster_two,\n",
    "    mode='lines',\n",
    "    line=dict(color='rgb(5, 0, 170)'),\n",
    "    fillcolor='rgba(29,96,141, 0.5)',\n",
    "    fill='tonexty',\n",
    "    opacity=0.8)\n",
    "\n",
    "lower_bound2 = go.Scatter(\n",
    "    name='Lower Bound Cluster 2',\n",
    "    x=dates,\n",
    "    y=mean_cluster_two-std_cluster_two,\n",
    "    marker=dict(color=\"#400\"),\n",
    "    line=dict(width=0),\n",
    "    mode='lines',\n",
    "    opacity=0.8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "upper_bound3 = go.Scatter(\n",
    "    name='Upper Bound Cluster 3',\n",
    "    x=dates,\n",
    "    y=mean_cluster_three+std_cluster_three,\n",
    "    mode='lines',\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(229,152,19, 0.5)',\n",
    "    fill='tonexty',\n",
    "    opacity=0.8)\n",
    "\n",
    "trace3 = go.Scatter(\n",
    "    name='Mean Cluster 3',\n",
    "    x=dates,\n",
    "    y=mean_cluster_three,\n",
    "    mode='lines',\n",
    "    line=dict(color='rgb(244, 122, 41)'),\n",
    "    fillcolor='rgba(229,152,19, 0.5)',\n",
    "    fill='tonexty',\n",
    "    opacity=0.8)\n",
    "\n",
    "lower_bound3 = go.Scatter(\n",
    "    name='Lower Bound Cluster 3',\n",
    "    x=dates,\n",
    "    y=mean_cluster_three-std_cluster_three,\n",
    "    marker=dict(color=\"#400\"),\n",
    "    line=dict(width=0),\n",
    "    mode='lines',\n",
    "    opacity=0.8)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = 0\n",
    "data_one = []\n",
    "for i in cluster_one_series:\n",
    "    trace = go.Scatter(\n",
    "    name='Cluster_One',\n",
    "    x=dates,\n",
    "    y=cluster_one_series[v],\n",
    "    mode='lines',\n",
    "    line=dict(color='rgba(100,150,65,0.5)'))\n",
    "    data_one.append(trace)\n",
    "    v+=1\n",
    "\n",
    "t = 0\n",
    "data_two = []\n",
    "for i in cluster_two_series:\n",
    "    trace = go.Scatter(\n",
    "    name='Cluster_Two',\n",
    "    x=dates,\n",
    "    y=cluster_two_series[t],\n",
    "    mode='lines',\n",
    "    line=dict(color='rgba(29,96,141, 0.1)'))\n",
    "    data_two.append(trace)\n",
    "    t+=1  \n",
    "    \n",
    "    \n",
    "z = 0\n",
    "data_three = []\n",
    "for i in cluster_three_series:\n",
    "    trace = go.Scatter(\n",
    "    name='Cluster_Three',\n",
    "    x=dates,\n",
    "    y=cluster_three_series[z],\n",
    "    mode='lines',\n",
    "    line=dict(color='rgba(229,152,19, 0.1)'))\n",
    "    data_three.append(trace)\n",
    "    z+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "\n",
    "# Trace order can be important\n",
    "# with continuous error bars\n",
    "data = [lower_bound1, trace1, upper_bound1, lower_bound2, trace2, upper_bound2, lower_bound3, trace3, upper_bound3]\n",
    "layout = go.Layout(\n",
    "    yaxis=dict(title='Normalised Number of Prescriptions'),\n",
    "    title='Cluster Comparison - Tramadol',\n",
    "    showlegend = True)\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='pandas-continuous-error-bars')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "trace0 = go.Scatter(\n",
    "    x = dates,\n",
    "    y = cluster_one_series[0],\n",
    "    mode = 'lines+markers',\n",
    "    name = 'Cluster 1 Example'\n",
    ")\n",
    "trace1 = go.Scatter(\n",
    "    x = dates,\n",
    "    y = cluster_two_series[0],\n",
    "    mode = 'lines+markers',\n",
    "    name = 'Cluster 2 Example'\n",
    ")\n",
    "\n",
    "\n",
    "trace2 = go.Scatter(\n",
    "    x = dates,\n",
    "    y = cluster_three_series[0],\n",
    "    mode = 'lines+markers',\n",
    "    name = 'Cluster 3 Example'\n",
    ")\n",
    "\n",
    "trace3 = go.Scatter(\n",
    "    x = dates,\n",
    "    y = cluster_four_series[0],\n",
    "    mode = 'lines+markers',\n",
    "    name = 'Cluster 4 Example'\n",
    ")\n",
    "\n",
    "trace4 = go.Scatter(\n",
    "    x = dates,\n",
    "    y = cluster_five_series[0],\n",
    "    mode = 'lines+markers',\n",
    "    name = 'Cluster 5 Example'\n",
    ")\n",
    "\n",
    "\n",
    "layout = dict(\n",
    "    title='Number of Prescriptions per Drug',\n",
    "    yaxis=dict(title = 'Number of Prescriptions per Drug'),\n",
    "    xaxis=dict(title = 'Year',\n",
    "        rangeselector=dict(\n",
    "            buttons=list([\n",
    "                dict(count=1,\n",
    "                     label='1m',\n",
    "                     step='month',\n",
    "                     stepmode='backward'),\n",
    "                dict(count=6,\n",
    "                     label='6m',\n",
    "                     step='month',\n",
    "                     stepmode='backward'),\n",
    "                dict(step='all')\n",
    "            ])\n",
    "        ),\n",
    "        rangeslider=dict(\n",
    "            visible = True\n",
    "        ),\n",
    "        type='date'\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "data = [trace0, trace1, trace2, trace3, trace4]\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "k=10\n",
    "b = fcluster(linked, k, criterion='maxclust')\n",
    "b = b.tolist()\n",
    "\n",
    "index_cluster_one = []\n",
    "index_cluster_two = []\n",
    "index_cluster_three = []\n",
    "index_cluster_four = []\n",
    "index_cluster_five = []\n",
    "index_cluster_six = []\n",
    "index_cluster_seven = []\n",
    "index_cluster_eight = []\n",
    "index_cluster_nine = []\n",
    "index_cluster_ten = []\n",
    "\n",
    "for c, value in enumerate(b, 0):\n",
    "    \n",
    "    if value == 1:\n",
    "        index_cluster_one.append(c)\n",
    "    elif value ==2:\n",
    "        index_cluster_two.append(c)\n",
    "    elif value ==3:\n",
    "        index_cluster_three.append(c)\n",
    "    elif value ==4:\n",
    "        index_cluster_four.append(c)\n",
    "    elif value == 5:\n",
    "        index_cluster_five.append(c)\n",
    "    elif value == 6:\n",
    "        index_cluster_six.append(c)\n",
    "    elif value == 7:\n",
    "        index_cluster_seven.append(c)\n",
    "    elif value == 8:\n",
    "        index_cluster_eight.append(c)\n",
    "    elif value == 9:\n",
    "        index_cluster_nine.append(c)\n",
    "    else:\n",
    "        index_cluster_ten.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print_clusters(individual_series, linked, 10, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "cluster_one_series = []\n",
    "for i in index_cluster_one:\n",
    "    cluster_one_series.append(individual_series[i])\n",
    "\n",
    "mean_cluster_one =  np.mean(cluster_one_series, axis=0)\n",
    "std_cluster_one = np.std(cluster_one_series, axis=0)\n",
    "\n",
    "\n",
    "cluster_two_series = []\n",
    "for i in index_cluster_two:\n",
    "    cluster_two_series.append(individual_series[i])\n",
    "\n",
    "mean_cluster_two =  np.mean(cluster_two_series, axis=0)\n",
    "std_cluster_two = np.std(cluster_two_series, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "cluster_three_series = []\n",
    "for i in index_cluster_three:\n",
    "    cluster_three_series.append(individual_series[i])\n",
    "\n",
    "mean_cluster_three =  np.mean(cluster_three_series, axis=0)\n",
    "std_cluster_three = np.std(cluster_three_series, axis=0)\n",
    "\n",
    "\n",
    "cluster_four_series = []\n",
    "for i in index_cluster_four:\n",
    "    cluster_four_series.append(individual_series[i])\n",
    "\n",
    "mean_cluster_four =  np.mean(cluster_four_series, axis=0)\n",
    "std_cluster_four = np.std(cluster_four_series, axis=0)\n",
    "\n",
    "\n",
    "cluster_five_series = []\n",
    "for i in index_cluster_five:\n",
    "    cluster_five_series.append(individual_series[i])\n",
    "\n",
    "mean_cluster_five =  np.mean(cluster_five_series, axis=0)\n",
    "std_cluster_five = np.std(cluster_five_series, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "cluster_six_series = []\n",
    "for i in index_cluster_six:\n",
    "    cluster_six_series.append(individual_series[i])\n",
    "\n",
    "mean_cluster_six =  np.mean(cluster_six_series, axis=0)\n",
    "std_cluster_six = np.std(cluster_six_series, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "cluster_seven_series = []\n",
    "for i in index_cluster_seven:\n",
    "    cluster_seven_series.append(individual_series[i])\n",
    "\n",
    "mean_cluster_seven =  np.mean(cluster_seven_series, axis=0)\n",
    "std_cluster_seven = np.std(cluster_seven_series, axis=0)\n",
    "\n",
    "cluster_eight_series = []\n",
    "for i in index_cluster_eight:\n",
    "    cluster_eight_series.append(individual_series[i])\n",
    "\n",
    "mean_cluster_eight =  np.mean(cluster_eight_series, axis=0)\n",
    "std_cluster_eight = np.std(cluster_eight_series, axis=0)\n",
    "\n",
    "\n",
    "cluster_nine_series = []\n",
    "for i in index_cluster_nine:\n",
    "    cluster_nine_series.append(individual_series[i])\n",
    "\n",
    "mean_cluster_nine =  np.mean(cluster_nine_series, axis=0)\n",
    "std_cluster_nine = np.std(cluster_nine_series, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "cluster_ten_series = []\n",
    "for i in index_cluster_ten:\n",
    "    cluster_ten_series.append(individual_series[i])\n",
    "\n",
    "mean_cluster_ten =  np.mean(cluster_ten_series, axis=0)\n",
    "std_cluster_ten = np.std(cluster_ten_series, axis=0)\n",
    "\n",
    "\n",
    "upper_bound1 = go.Scatter(\n",
    "    name='Upper Bound Cluster 1',\n",
    "    x=dates,\n",
    "    y=mean_cluster_one+std_cluster_one,\n",
    "    mode='lines',\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(90,150,65,0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    name='Mean Cluster 1',\n",
    "    x=dates,\n",
    "    y=mean_cluster_one,\n",
    "    mode='lines',\n",
    "    line=dict(color='red'),\n",
    "    fillcolor='rgba(90,150,65,0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "lower_bound1 = go.Scatter(\n",
    "    name='Lower Bound Cluster 1',\n",
    "    x=dates,\n",
    "    y=mean_cluster_one-std_cluster_one,\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    mode='lines')\n",
    "\n",
    "\n",
    "upper_bound2 = go.Scatter(\n",
    "    name='Upper Bound Cluster 2',\n",
    "    x=dates,\n",
    "    y=mean_cluster_two+std_cluster_two,\n",
    "    mode='lines',\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(29,96, 141, 0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "trace2 = go.Scatter(\n",
    "    name='Mean Cluster 2',\n",
    "    x=dates,\n",
    "    y=mean_cluster_two,\n",
    "    mode='lines',\n",
    "    line=dict(color='red'),\n",
    "    fillcolor='rgba(29,96, 141, 0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "lower_bound2 = go.Scatter(\n",
    "    name='Lower Bound Cluster 2',\n",
    "    x=dates,\n",
    "    y=mean_cluster_two-std_cluster_two,\n",
    "    marker=dict(color=\"#400\"),\n",
    "    line=dict(width=0),\n",
    "    mode='lines')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "upper_bound3 = go.Scatter(\n",
    "    name='Upper Bound Cluster 3',\n",
    "    x=dates,\n",
    "    y=mean_cluster_three+std_cluster_three,\n",
    "    mode='lines',\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(229,152,19, 0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "trace3 = go.Scatter(\n",
    "    name='Mean Cluster 3',\n",
    "    x=dates,\n",
    "    y=mean_cluster_three,\n",
    "    mode='lines',\n",
    "    line=dict(color='red'),\n",
    "    fillcolor='rgba(229,152,19, 0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "lower_bound3 = go.Scatter(\n",
    "    name='Lower Bound Cluster 3',\n",
    "    x=dates,\n",
    "    y=mean_cluster_three-std_cluster_three,\n",
    "    marker=dict(color=\"#400\"),\n",
    "    line=dict(width=0),\n",
    "    mode='lines')\n",
    "\n",
    "\n",
    "\n",
    "upper_bound4 = go.Scatter(\n",
    "    name='Upper Bound Cluster 4',\n",
    "    x=dates,\n",
    "    y=mean_cluster_four+std_cluster_four,\n",
    "    mode='lines',\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(255,67,10, 0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "trace4 = go.Scatter(\n",
    "    name='Mean Cluster 4',\n",
    "    x=dates,\n",
    "    y=mean_cluster_four,\n",
    "    mode='lines',\n",
    "    line=dict(color='red'),\n",
    "    fillcolor='rgba(255,67,10, 0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "lower_bound4 = go.Scatter(\n",
    "    name='Lower Bound Cluster 4',\n",
    "    x=dates,\n",
    "    y=mean_cluster_four-std_cluster_four,\n",
    "    marker=dict(color=\"#50\"),\n",
    "    line=dict(width=0),\n",
    "    mode='lines')\n",
    "\n",
    "\n",
    "upper_bound5 = go.Scatter(\n",
    "    name='Upper Bound Cluster 5',\n",
    "    x=dates,\n",
    "    y=mean_cluster_five+std_cluster_five,\n",
    "    mode='lines',\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(255,10,240, 0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "trace5 = go.Scatter(\n",
    "    name='Mean Cluster 5',\n",
    "    x=dates,\n",
    "    y=mean_cluster_five,\n",
    "    mode='lines',\n",
    "    line=dict(color='red'),\n",
    "    fillcolor='rgba(255,10,240, 0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "lower_bound5 = go.Scatter(\n",
    "    name='Lower Bound Cluster 5',\n",
    "    x=dates,\n",
    "    y=mean_cluster_five-std_cluster_five,\n",
    "    marker=dict(color=\"#50\"),\n",
    "    line=dict(width=0),\n",
    "    mode='lines')\n",
    "\n",
    "\n",
    "upper_bound6 = go.Scatter(\n",
    "    name='Upper Bound Cluster 6',\n",
    "    x=dates,\n",
    "    y=mean_cluster_six+std_cluster_six,\n",
    "    mode='lines',\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(90,150,65,0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "trace6 = go.Scatter(\n",
    "    name='Mean Cluster 6',\n",
    "    x=dates,\n",
    "    y=mean_cluster_six,\n",
    "    mode='lines',\n",
    "    line=dict(color='red'),\n",
    "    fillcolor='rgba(90,150,65,0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "lower_bound6 = go.Scatter(\n",
    "    name='Lower Bound Cluster 6',\n",
    "    x=dates,\n",
    "    y=mean_cluster_six-std_cluster_six,\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    mode='lines')\n",
    "\n",
    "\n",
    "upper_bound7 = go.Scatter(\n",
    "    name='Upper Bound Cluster 7',\n",
    "    x=dates,\n",
    "    y=mean_cluster_seven+std_cluster_seven,\n",
    "    mode='lines',\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(29,96, 141, 0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "trace7 = go.Scatter(\n",
    "    name='Mean Cluster 7',\n",
    "    x=dates,\n",
    "    y=mean_cluster_seven,\n",
    "    mode='lines',\n",
    "    line=dict(color='red'),\n",
    "    fillcolor='rgba(29,96, 141, 0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "lower_bound7 = go.Scatter(\n",
    "    name='Lower Bound Cluster 7',\n",
    "    x=dates,\n",
    "    y=mean_cluster_seven-std_cluster_seven,\n",
    "    marker=dict(color=\"#400\"),\n",
    "    line=dict(width=0),\n",
    "    mode='lines')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "upper_bound8 = go.Scatter(\n",
    "    name='Upper Bound Cluster 8',\n",
    "    x=dates,\n",
    "    y=mean_cluster_eight+std_cluster_eight,\n",
    "    mode='lines',\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(229,152,19, 0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "trace8 = go.Scatter(\n",
    "    name='Mean Cluster 8',\n",
    "    x=dates,\n",
    "    y=mean_cluster_eight,\n",
    "    mode='lines',\n",
    "    line=dict(color='red'),\n",
    "    fillcolor='rgba(229,152,19, 0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "lower_bound8 = go.Scatter(\n",
    "    name='Lower Bound Cluster 8',\n",
    "    x=dates,\n",
    "    y=mean_cluster_eight-std_cluster_eight,\n",
    "    marker=dict(color=\"#400\"),\n",
    "    line=dict(width=0),\n",
    "    mode='lines')\n",
    "\n",
    "\n",
    "\n",
    "upper_bound9 = go.Scatter(\n",
    "    name='Upper Bound Cluster 9',\n",
    "    x=dates,\n",
    "    y=mean_cluster_nine+std_cluster_nine,\n",
    "    mode='lines',\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(255,67,10, 0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "trace9 = go.Scatter(\n",
    "    name='Mean Cluster 9',\n",
    "    x=dates,\n",
    "    y=mean_cluster_nine,\n",
    "    mode='lines',\n",
    "    line=dict(color='red'),\n",
    "    fillcolor='rgba(255,67,10, 0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "lower_bound9 = go.Scatter(\n",
    "    name='Lower Bound Cluster 9',\n",
    "    x=dates,\n",
    "    y=mean_cluster_nine-std_cluster_nine,\n",
    "    marker=dict(color=\"#50\"),\n",
    "    line=dict(width=0),\n",
    "    mode='lines')\n",
    "\n",
    "\n",
    "upper_bound10 = go.Scatter(\n",
    "    name='Upper Bound Cluster 10',\n",
    "    x=dates,\n",
    "    y=mean_cluster_ten+std_cluster_ten,\n",
    "    mode='lines',\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(255,10,240, 0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "trace10 = go.Scatter(\n",
    "    name='Mean Cluster 10',\n",
    "    x=dates,\n",
    "    y=mean_cluster_ten,\n",
    "    mode='lines',\n",
    "    line=dict(color='red'),\n",
    "    fillcolor='rgba(255,10,240, 0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "lower_bound10 = go.Scatter(\n",
    "    name='Lower Bound Cluster 10',\n",
    "    x=dates,\n",
    "    y=mean_cluster_ten-std_cluster_ten,\n",
    "    marker=dict(color=\"#50\"),\n",
    "    line=dict(width=0),\n",
    "    mode='lines')\n",
    "\n",
    "\n",
    "# Trace order can be important\n",
    "# with continuous error bars\n",
    "data = [lower_bound1, trace1, upper_bound1, lower_bound2, trace2, upper_bound2, lower_bound3, trace3, upper_bound3, lower_bound4, trace4, upper_bound4, lower_bound5, trace5, upper_bound5, lower_bound6, trace6, upper_bound6, lower_bound7, trace7, upper_bound7, lower_bound8, trace8, upper_bound8, lower_bound9, trace9, upper_bound9, lower_bound10, trace10, upper_bound10]\n",
    "layout = go.Layout(\n",
    "    yaxis=dict(title='Normalised Number of Prescriptions'),\n",
    "    title='Cluster Comparison - Tramadol',\n",
    "    showlegend = True)\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='pandas-continuous-error-bars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = individual_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_series = []\n",
    "\n",
    "for series in v:\n",
    "    short_series.append(series[60:])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linked_two = hac.linkage(short_series, method='average', metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(25, 15))\n",
    "plt.title('Hierarchical Clustering Dendrogram - Tramadol Prescriptions')\n",
    "plt.xlabel('CCG')\n",
    "plt.ylabel('Distance')\n",
    "hac.dendrogram(\n",
    "    linked,\n",
    "    leaf_rotation=90.,  # rotates the x axis labels\n",
    "    leaf_font_size=8.,  # font size for the x axis labels\n",
    "labels = ninety_practices)\n",
    "plt.show()\n",
    "\n",
    "print(f\"This shows a clustering of {len(individual_series) - len(not_full_time)} practices.\")\n",
    "\n",
    "\n",
    "c, coph_dists = hac.cophenet(linked_two, pdist(short_series))\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.metrics as met\n",
    "\n",
    "\n",
    "CH_SCORES = []\n",
    "u = 0\n",
    "for k in range(2, 30):\n",
    "    linked = hac.linkage(short_series, method='average', metric='euclidean')\n",
    "    labels = fcluster(linked, k, criterion='maxclust')\n",
    "    CH_score = met.calinski_harabaz_score(individual_series, labels)\n",
    "    CH_SCORES.append(CH_score)\n",
    "    print(f'Complete {u}')\n",
    "    u +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=6\n",
    "b = fcluster(linked_two, k, criterion='maxclust')\n",
    "b = b.tolist()\n",
    "\n",
    "index_cluster_one = []\n",
    "index_cluster_two = []\n",
    "index_cluster_three = []\n",
    "index_cluster_four = []\n",
    "index_cluster_five = []\n",
    "index_cluster_six = []\n",
    "index_cluster_seven = []\n",
    "index_cluster_eight = []\n",
    "index_cluster_nine = []\n",
    "index_cluster_ten = []\n",
    "\n",
    "for c, value in enumerate(b, 0):\n",
    "    \n",
    "    if value == 1:\n",
    "        index_cluster_one.append(c)\n",
    "    elif value ==2:\n",
    "        index_cluster_two.append(c)\n",
    "    elif value ==3:\n",
    "        index_cluster_three.append(c)\n",
    "    elif value ==4:\n",
    "        index_cluster_four.append(c)\n",
    "    elif value == 5:\n",
    "        index_cluster_five.append(c)\n",
    "    elif value == 6:\n",
    "        index_cluster_six.append(c)\n",
    "    elif value == 7:\n",
    "        index_cluster_seven.append(c)\n",
    "    elif value == 8:\n",
    "        index_cluster_eight.append(c)\n",
    "    elif value == 9:\n",
    "        index_cluster_nine.append(c)\n",
    "    else:\n",
    "        index_cluster_ten.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_clusters(short_series, linked_two, 6, plot=False)\n",
    "\n",
    "dates = dates[60:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_one_series = []\n",
    "for i in index_cluster_one:\n",
    "    cluster_one_series.append(short_series[i])\n",
    "\n",
    "mean_cluster_one =  np.mean(cluster_one_series, axis=0)\n",
    "std_cluster_one = np.std(cluster_one_series, axis=0)\n",
    "\n",
    "\n",
    "cluster_two_series = []\n",
    "for i in index_cluster_two:\n",
    "    cluster_two_series.append(short_series[i])\n",
    "\n",
    "mean_cluster_two =  np.mean(cluster_two_series, axis=0)\n",
    "std_cluster_two = np.std(cluster_two_series, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "cluster_three_series = []\n",
    "for i in index_cluster_three:\n",
    "    cluster_three_series.append(short_series[i])\n",
    "\n",
    "mean_cluster_three =  np.mean(cluster_three_series, axis=0)\n",
    "std_cluster_three = np.std(cluster_three_series, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "cluster_four_series = []\n",
    "for i in index_cluster_four:\n",
    "    cluster_four_series.append(short_series[i])\n",
    "\n",
    "mean_cluster_four =  np.mean(cluster_four_series, axis=0)\n",
    "std_cluster_four = np.std(cluster_four_series, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "cluster_five_series = []\n",
    "for i in index_cluster_five:\n",
    "    cluster_five_series.append(short_series[i])\n",
    "\n",
    "mean_cluster_five =  np.mean(cluster_five_series, axis=0)\n",
    "std_cluster_five = np.std(cluster_five_series, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "cluster_six_series = []\n",
    "for i in index_cluster_six:\n",
    "    cluster_six_series.append(short_series[i])\n",
    "\n",
    "mean_cluster_six =  np.mean(cluster_six_series, axis=0)\n",
    "std_cluster_six = np.std(cluster_six_series, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "upper_bound1 = go.Scatter(\n",
    "    opacity=0.8,\n",
    "    name='Upper Bound Cluster 1',\n",
    "    x=dates,\n",
    "    y=mean_cluster_one+std_cluster_one,\n",
    "    mode='lines',\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(10,150,65,0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    opacity=0.8,\n",
    "    name='Mean Cluster 1',\n",
    "    x=dates,\n",
    "    y=mean_cluster_one,\n",
    "    mode='lines',\n",
    "    line=dict(color='rgb(0, 255, 93)'),\n",
    "    fillcolor='rgba(10,150,65,0.5)',\n",
    "    fill='tonexty' \n",
    "   )\n",
    "\n",
    "lower_bound1 = go.Scatter(\n",
    "    opacity=0.8,\n",
    "    name='Lower Bound Cluster 1',\n",
    "    x=dates,\n",
    "    y=mean_cluster_one-std_cluster_one,\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    mode='lines')\n",
    "\n",
    "\n",
    "upper_bound2 = go.Scatter(\n",
    "    name='Upper Bound Cluster 2',\n",
    "    x=dates,\n",
    "    y=mean_cluster_two+std_cluster_two,\n",
    "    mode='lines',\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(29,96, 141, 0.5)',\n",
    "    fill='tonexty',\n",
    "    opacity = 0.8)\n",
    "\n",
    "trace2 = go.Scatter(\n",
    "    name='Mean Cluster 2',\n",
    "    x=dates,\n",
    "    y=mean_cluster_two,\n",
    "    mode='lines',\n",
    "    line=dict(color='rgb(5, 0, 170)'),\n",
    "    fillcolor='rgba(29,96,141, 0.5)',\n",
    "    fill='tonexty',\n",
    "    opacity=0.8)\n",
    "\n",
    "lower_bound2 = go.Scatter(\n",
    "    name='Lower Bound Cluster 2',\n",
    "    x=dates,\n",
    "    y=mean_cluster_two-std_cluster_two,\n",
    "    marker=dict(color=\"#400\"),\n",
    "    line=dict(width=0),\n",
    "    mode='lines',\n",
    "    opacity=0.8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "upper_bound3 = go.Scatter(\n",
    "    name='Upper Bound Cluster 3',\n",
    "    x=dates,\n",
    "    y=mean_cluster_three+std_cluster_three,\n",
    "    mode='lines',\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(250,13,13, 0.5)',\n",
    "    fill='tonexty',\n",
    "    opacity=0.8)\n",
    "\n",
    "trace3 = go.Scatter(\n",
    "    name='Mean Cluster 3',\n",
    "    x=dates,\n",
    "    y=mean_cluster_three,\n",
    "    mode='lines',\n",
    "    line=dict(color='rgb(250, 13, 13)'),\n",
    "    fillcolor='rgba(250,13,13, 0.5)',\n",
    "    fill='tonexty',\n",
    "    opacity=0.8)\n",
    "\n",
    "lower_bound3 = go.Scatter(\n",
    "    name='Lower Bound Cluster 3',\n",
    "    x=dates,\n",
    "    y=mean_cluster_three-std_cluster_three,\n",
    "    marker=dict(color=\"#400\"),\n",
    "    line=dict(width=0),\n",
    "    mode='lines',\n",
    "    opacity=0.8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "upper_bound4 = go.Scatter(\n",
    "    name='Upper Bound Cluster 4',\n",
    "    x=dates,\n",
    "    y=mean_cluster_four+std_cluster_four,\n",
    "    mode='lines',\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(232,239,31, 0.5)',\n",
    "    fill='tonexty',\n",
    "    opacity=0.8)\n",
    "\n",
    "trace4 = go.Scatter(\n",
    "    name='Mean Cluster 4',\n",
    "    x=dates,\n",
    "    y=mean_cluster_four,\n",
    "    mode='lines',\n",
    "    line=dict(color='rgb(232, 239, 31)'),\n",
    "    fillcolor='rgba(232,239,31, 0.5)',\n",
    "    fill='tonexty',\n",
    "    opacity=0.8)\n",
    "\n",
    "lower_bound4 = go.Scatter(\n",
    "    name='Lower Bound Cluster 4',\n",
    "    x=dates,\n",
    "    y=mean_cluster_four-std_cluster_four,\n",
    "    marker=dict(color=\"#400\"),\n",
    "    line=dict(width=0),\n",
    "    mode='lines',\n",
    "    opacity=0.8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "upper_bound5 = go.Scatter(\n",
    "    name='Upper Bound Cluster 5',\n",
    "    x=dates,\n",
    "    y=mean_cluster_five+std_cluster_five,\n",
    "    mode='lines',\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(252, 164, 2, 0.5)',\n",
    "    fill='tonexty',\n",
    "    opacity=0.8)\n",
    "\n",
    "trace5 = go.Scatter(\n",
    "    name='Mean Cluster 5',\n",
    "    x=dates,\n",
    "    y=mean_cluster_five,\n",
    "    mode='lines',\n",
    "    line=dict(color='rgb(252, 164, 2)'),\n",
    "    fillcolor='rgba(252, 164, 2, 0.5)',\n",
    "    fill='tonexty',\n",
    "    opacity=0.8)\n",
    "\n",
    "lower_bound5 = go.Scatter(\n",
    "    name='Lower Bound Cluster 5',\n",
    "    x=dates,\n",
    "    y=mean_cluster_five-std_cluster_five,\n",
    "    marker=dict(color=\"#400\"),\n",
    "    line=dict(width=0),\n",
    "    mode='lines',\n",
    "    opacity=0.8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "upper_bound6 = go.Scatter(\n",
    "    opacity=0.8,\n",
    "    name='Upper Bound Cluster 6',\n",
    "    x=dates,\n",
    "    y=mean_cluster_six+std_cluster_six,\n",
    "    mode='lines',\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(153, 0, 147, 0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "trace6= go.Scatter(\n",
    "    name='Mean Cluster 6',\n",
    "    x=dates,\n",
    "    y=mean_cluster_six,\n",
    "    mode='lines',\n",
    "    line=dict(color='rgb(153, 0, 147)'),\n",
    "    fillcolor='rgba(153, 0, 147, 0.5)',\n",
    "    fill='tonexty',\n",
    "    opacity=0.8)\n",
    "\n",
    "lower_bound6 = go.Scatter(\n",
    "    name='Lower Bound Cluster 6',\n",
    "    x=dates,\n",
    "    y=mean_cluster_six-std_cluster_six,\n",
    "    marker=dict(color=\"#400\"),\n",
    "    line=dict(width=0),\n",
    "    mode='lines',\n",
    "    opacity=0.8)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trace order can be important\n",
    "# with continuous error bars\n",
    "data2 = [lower_bound1, trace1, upper_bound1, lower_bound2, trace2, upper_bound2, lower_bound3, trace3, upper_bound3, lower_bound4, trace4, upper_bound4, lower_bound5, trace5, upper_bound5, lower_bound6, trace6, upper_bound6]\n",
    "layout = go.Layout(\n",
    "    yaxis=dict(title='Normalised Number of Prescriptions'),\n",
    "    title='Cluster Comparison - Tramadol',\n",
    "    showlegend = True)\n",
    "\n",
    "fig = go.Figure(data=data2, layout=layout)\n",
    "py.iplot(fig, filename='pandas-continuous-error-bars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = 0\n",
    "data_one = []\n",
    "for i in cluster_one_series:\n",
    "    trace = go.Scatter(\n",
    "    name='Cluster_One',\n",
    "    x=dates,\n",
    "    y=cluster_one_series[v],\n",
    "    mode='lines',\n",
    "    line=dict(color='rgba(100,150,65,0.2)'))\n",
    "    data_one.append(trace)\n",
    "    v+=1\n",
    "\n",
    "t = 0\n",
    "data_two = []\n",
    "for i in cluster_two_series:\n",
    "    trace = go.Scatter(\n",
    "    name='Cluster_Two',\n",
    "    x=dates,\n",
    "    y=cluster_two_series[t],\n",
    "    mode='lines',\n",
    "    line=dict(color='rgba(29,96,141, 0.2)'))\n",
    "    data_two.append(trace)\n",
    "    t+=1  \n",
    "    \n",
    "    \n",
    "z = 0\n",
    "data_three = []\n",
    "for i in cluster_three_series:\n",
    "    trace = go.Scatter(\n",
    "    name='Cluster_Three',\n",
    "    x=dates,\n",
    "    y=cluster_three_series[z],\n",
    "    mode='lines',\n",
    "    line=dict(color='rgba(250,13,13, 0.2)'))\n",
    "    data_three.append(trace)\n",
    "    z+=1\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "z = 0\n",
    "data_four = []\n",
    "for i in cluster_four_series:\n",
    "    trace = go.Scatter(\n",
    "    name='Cluster_Four',\n",
    "    x=dates,\n",
    "    y=cluster_four_series[z],\n",
    "    mode='lines',\n",
    "    line=dict(color='rgba(232,239,31, 0.2)'))\n",
    "    data_four.append(trace)\n",
    "    z+=1\n",
    "    \n",
    "    \n",
    "z = 0\n",
    "data_five = []\n",
    "for i in cluster_five_series:\n",
    "    trace = go.Scatter(\n",
    "    name='Cluster_Five',\n",
    "    x=dates,\n",
    "    y=cluster_five_series[z],\n",
    "    mode='lines',\n",
    "    line=dict(color='rgba(252, 164, 2, 0.2)'))\n",
    "    data_five.append(trace)\n",
    "    z+=1\n",
    "              \n",
    "              \n",
    "              \n",
    "z = 0\n",
    "data_six = []\n",
    "for i in cluster_six_series:\n",
    "    trace = go.Scatter(\n",
    "    name='Cluster_Six',\n",
    "    x=dates,\n",
    "    y=cluster_six_series[z],\n",
    "    mode='lines',\n",
    "    line=dict(color='rgba(153, 0, 147, 0.2)'))\n",
    "    data_six.append(trace)\n",
    "    z+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "\n",
    "# Trace order can be important\n",
    "# with continuous error bars\n",
    "data = [lower_bound1, trace1, upper_bound1, lower_bound2, trace2, upper_bound2, lower_bound3, trace3, upper_bound3, lower_bound4, trace4, upper_bound4, lower_bound5, trace5, upper_bound5, lower_bound6, trace6, upper_bound6]\n",
    "layout = go.Layout(\n",
    "    yaxis=dict(title='Normalised Number of Prescriptions'),\n",
    "    title='Cluster Comparison - Tramadol',\n",
    "    showlegend = True)\n",
    "\n",
    "fig = go.Figure(data= data_one + data_two + data_three + data_four + random.sample(data_five, 200) + random.sample(data_six, 200) +data, layout=layout)\n",
    "py.iplot(fig, filename='pandas-continuous-error-bars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_of_interest = []\n",
    "for series in only_ninety_six:\n",
    "    shortened = series[60:]\n",
    "    series_of_interest.append(shortened)\n",
    "\n",
    "data_four_interested = []\n",
    "for i in index_cluster_four:\n",
    "    data_four_interested.append(series_of_interest[i])\n",
    "\n",
    "\n",
    "    \n",
    "smoothed_normalised = []\n",
    "\n",
    "\n",
    "for time_series in data_four_interested:\n",
    "    a=time_series\n",
    "    #a = sc.savgol_filter(time_series, 5, 2)\n",
    "    smoothed_normalised.append(a)\n",
    "  \n",
    "\n",
    "\n",
    "z = 0\n",
    "data=[]\n",
    "for i in smoothed_normalised:\n",
    "    trace = go.Scatter(\n",
    "    name='Cluster_Four',\n",
    "    x=dates,\n",
    "    y=data_four_interested[z],\n",
    "    mode='lines',\n",
    "    line=dict(color='rgb(232,239,31)'))\n",
    "    data.append(trace)\n",
    "    z+=1\n",
    "    \n",
    "    \n",
    "\n",
    "layout = go.Layout(\n",
    "    yaxis=dict(title='Number of Prescriptions'),\n",
    "    title='Cluster 4 Raw Traces',\n",
    "    showlegend = True)\n",
    "\n",
    "fig = go.Figure(data= data, layout=layout)\n",
    "py.iplot(fig, filename='pandas-continuous-error-bars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_one_series = []\n",
    "for i in index_cluster_one:\n",
    "    cluster_one_series.append(short_series[i])\n",
    "\n",
    "mean_cluster_one =  np.mean(cluster_one_series, axis=0)\n",
    "std_cluster_one = np.std(cluster_one_series, axis=0)\n",
    "\n",
    "\n",
    "cluster_two_series = []\n",
    "for i in index_cluster_two:\n",
    "    cluster_two_series.append(short_series[i])\n",
    "\n",
    "mean_cluster_two =  np.mean(cluster_two_series, axis=0)\n",
    "std_cluster_two = np.std(cluster_two_series, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "cluster_three_series = []\n",
    "for i in index_cluster_three:\n",
    "    cluster_three_series.append(short_series[i])\n",
    "\n",
    "mean_cluster_three =  np.mean(cluster_three_series, axis=0)\n",
    "std_cluster_three = np.std(cluster_three_series, axis=0)\n",
    "\n",
    "\n",
    "cluster_four_series = []\n",
    "for i in index_cluster_four:\n",
    "    cluster_four_series.append(short_series[i])\n",
    "\n",
    "mean_cluster_four =  np.mean(cluster_four_series, axis=0)\n",
    "std_cluster_four = np.std(cluster_four_series, axis=0)\n",
    "\n",
    "\n",
    "cluster_five_series = []\n",
    "for i in index_cluster_five:\n",
    "    cluster_five_series.append(short_series[i])\n",
    "\n",
    "mean_cluster_five =  np.mean(cluster_five_series, axis=0)\n",
    "std_cluster_five = np.std(cluster_five_series, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "cluster_six_series = []\n",
    "for i in index_cluster_six:\n",
    "    cluster_six_series.append(short_series[i])\n",
    "\n",
    "mean_cluster_six =  np.mean(cluster_six_series, axis=0)\n",
    "std_cluster_six = np.std(cluster_six_series, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "cluster_seven_series = []\n",
    "for i in index_cluster_seven:\n",
    "    cluster_seven_series.append(short_series[i])\n",
    "\n",
    "mean_cluster_seven =  np.mean(cluster_seven_series, axis=0)\n",
    "std_cluster_seven = np.std(cluster_seven_series, axis=0)\n",
    "\n",
    "cluster_eight_series = []\n",
    "for i in index_cluster_eight:\n",
    "    cluster_eight_series.append(short_series[i])\n",
    "\n",
    "mean_cluster_eight =  np.mean(cluster_eight_series, axis=0)\n",
    "std_cluster_eight = np.std(cluster_eight_series, axis=0)\n",
    "\n",
    "\n",
    "cluster_nine_series = []\n",
    "for i in index_cluster_nine:\n",
    "    cluster_nine_series.append(short_series[i])\n",
    "\n",
    "mean_cluster_nine =  np.mean(cluster_nine_series, axis=0)\n",
    "std_cluster_nine = np.std(cluster_nine_series, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "cluster_ten_series = []\n",
    "for i in index_cluster_ten:\n",
    "    cluster_ten_series.append(short_series[i])\n",
    "\n",
    "mean_cluster_ten =  np.mean(cluster_ten_series, axis=0)\n",
    "std_cluster_ten = np.std(cluster_ten_series, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "print(mean_cluster_ten)\n",
    "upper_bound1 = go.Scatter(\n",
    "    name='Upper Bound Cluster 1',\n",
    "    x=dates,\n",
    "    y=mean_cluster_one+std_cluster_one,\n",
    "    mode='lines',\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(90,150,65,0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    name='Mean Cluster 1',\n",
    "    x=dates,\n",
    "    y=mean_cluster_one,\n",
    "    mode='lines',\n",
    "    line=dict(color='red'),\n",
    "    fillcolor='rgba(90,150,65,0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "lower_bound1 = go.Scatter(\n",
    "    name='Lower Bound Cluster 1',\n",
    "    x=dates,\n",
    "    y=mean_cluster_one-std_cluster_one,\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    mode='lines')\n",
    "\n",
    "\n",
    "upper_bound2 = go.Scatter(\n",
    "    name='Upper Bound Cluster 2',\n",
    "    x=dates,\n",
    "    y=mean_cluster_two+std_cluster_two,\n",
    "    mode='lines',\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(29,96, 141, 0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "trace2 = go.Scatter(\n",
    "    name='Mean Cluster 2',\n",
    "    x=dates,\n",
    "    y=mean_cluster_two,\n",
    "    mode='lines',\n",
    "    line=dict(color='red'),\n",
    "    fillcolor='rgba(29,96, 141, 0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "lower_bound2 = go.Scatter(\n",
    "    name='Lower Bound Cluster 2',\n",
    "    x=dates,\n",
    "    y=mean_cluster_two-std_cluster_two,\n",
    "    marker=dict(color=\"#400\"),\n",
    "    line=dict(width=0),\n",
    "    mode='lines')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "upper_bound3 = go.Scatter(\n",
    "    name='Upper Bound Cluster 3',\n",
    "    x=dates,\n",
    "    y=mean_cluster_three+std_cluster_three,\n",
    "    mode='lines',\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(229,152,19, 0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "trace3 = go.Scatter(\n",
    "    name='Mean Cluster 3',\n",
    "    x=dates,\n",
    "    y=mean_cluster_three,\n",
    "    mode='lines',\n",
    "    line=dict(color='red'),\n",
    "    fillcolor='rgba(229,152,19, 0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "lower_bound3 = go.Scatter(\n",
    "    name='Lower Bound Cluster 3',\n",
    "    x=dates,\n",
    "    y=mean_cluster_three-std_cluster_three,\n",
    "    marker=dict(color=\"#400\"),\n",
    "    line=dict(width=0),\n",
    "    mode='lines')\n",
    "\n",
    "\n",
    "\n",
    "upper_bound4 = go.Scatter(\n",
    "    name='Upper Bound Cluster 4',\n",
    "    x=dates,\n",
    "    y=mean_cluster_four+std_cluster_four,\n",
    "    mode='lines',\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(255,67,10, 0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "trace4 = go.Scatter(\n",
    "    name='Mean Cluster 4',\n",
    "    x=dates,\n",
    "    y=mean_cluster_four,\n",
    "    mode='lines',\n",
    "    line=dict(color='red'),\n",
    "    fillcolor='rgba(255,67,10, 0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "lower_bound4 = go.Scatter(\n",
    "    name='Lower Bound Cluster 4',\n",
    "    x=dates,\n",
    "    y=mean_cluster_four-std_cluster_four,\n",
    "    marker=dict(color=\"#50\"),\n",
    "    line=dict(width=0),\n",
    "    mode='lines')\n",
    "\n",
    "\n",
    "upper_bound5 = go.Scatter(\n",
    "    name='Upper Bound Cluster 5',\n",
    "    x=dates,\n",
    "    y=mean_cluster_five+std_cluster_five,\n",
    "    mode='lines',\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(255,10,240, 0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "trace5 = go.Scatter(\n",
    "    name='Mean Cluster 5',\n",
    "    x=dates,\n",
    "    y=mean_cluster_five,\n",
    "    mode='lines',\n",
    "    line=dict(color='red'),\n",
    "    fillcolor='rgba(255,10,240, 0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "lower_bound5 = go.Scatter(\n",
    "    name='Lower Bound Cluster 5',\n",
    "    x=dates,\n",
    "    y=mean_cluster_five-std_cluster_five,\n",
    "    marker=dict(color=\"#50\"),\n",
    "    line=dict(width=0),\n",
    "    mode='lines')\n",
    "\n",
    "\n",
    "upper_bound6 = go.Scatter(\n",
    "    name='Upper Bound Cluster 6',\n",
    "    x=dates,\n",
    "    y=mean_cluster_six+std_cluster_six,\n",
    "    mode='lines',\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(90,150,65,0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "trace6 = go.Scatter(\n",
    "    name='Mean Cluster 6',\n",
    "    x=dates,\n",
    "    y=mean_cluster_six,\n",
    "    mode='lines',\n",
    "    line=dict(color='red'),\n",
    "    fillcolor='rgba(90,150,65,0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "lower_bound6 = go.Scatter(\n",
    "    name='Lower Bound Cluster 6',\n",
    "    x=dates,\n",
    "    y=mean_cluster_six-std_cluster_six,\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    mode='lines')\n",
    "\n",
    "\n",
    "upper_bound7 = go.Scatter(\n",
    "    name='Upper Bound Cluster 7',\n",
    "    x=dates,\n",
    "    y=mean_cluster_seven+std_cluster_seven,\n",
    "    mode='lines',\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(29,96, 141, 0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "trace7 = go.Scatter(\n",
    "    name='Mean Cluster 7',\n",
    "    x=dates,\n",
    "    y=mean_cluster_seven,\n",
    "    mode='lines',\n",
    "    line=dict(color='red'),\n",
    "    fillcolor='rgba(29,96, 141, 0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "lower_bound7 = go.Scatter(\n",
    "    name='Lower Bound Cluster 7',\n",
    "    x=dates,\n",
    "    y=mean_cluster_seven-std_cluster_seven,\n",
    "    marker=dict(color=\"#400\"),\n",
    "    line=dict(width=0),\n",
    "    mode='lines')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "upper_bound8 = go.Scatter(\n",
    "    name='Upper Bound Cluster 8',\n",
    "    x=dates,\n",
    "    y=mean_cluster_eight+std_cluster_eight,\n",
    "    mode='lines',\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(229,152,19, 0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "trace8 = go.Scatter(\n",
    "    name='Mean Cluster 8',\n",
    "    x=dates,\n",
    "    y=mean_cluster_eight,\n",
    "    mode='lines',\n",
    "    line=dict(color='red'),\n",
    "    fillcolor='rgba(229,152,19, 0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "lower_bound8 = go.Scatter(\n",
    "    name='Lower Bound Cluster 8',\n",
    "    x=dates,\n",
    "    y=mean_cluster_eight-std_cluster_eight,\n",
    "    marker=dict(color=\"#400\"),\n",
    "    line=dict(width=0),\n",
    "    mode='lines')\n",
    "\n",
    "\n",
    "\n",
    "upper_bound9 = go.Scatter(\n",
    "    name='Upper Bound Cluster 9',\n",
    "    x=dates,\n",
    "    y=mean_cluster_nine+std_cluster_nine,\n",
    "    mode='lines',\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(255,67,10, 0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "trace9 = go.Scatter(\n",
    "    name='Mean Cluster 9',\n",
    "    x=dates,\n",
    "    y=mean_cluster_nine,\n",
    "    mode='lines',\n",
    "    line=dict(color='red'),\n",
    "    fillcolor='rgba(255,67,10, 0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "lower_bound9 = go.Scatter(\n",
    "    name='Lower Bound Cluster 9',\n",
    "    x=dates,\n",
    "    y=mean_cluster_nine-std_cluster_nine,\n",
    "    marker=dict(color=\"#50\"),\n",
    "    line=dict(width=0),\n",
    "    mode='lines')\n",
    "\n",
    "\n",
    "upper_bound10 = go.Scatter(\n",
    "    name='Upper Bound Cluster 10',\n",
    "    x=dates,\n",
    "    y=mean_cluster_ten+std_cluster_ten,\n",
    "    mode='lines',\n",
    "    marker=dict(color=\"#444\"),\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(255,10,240, 0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "trace10 = go.Scatter(\n",
    "    name='Mean Cluster 10',\n",
    "    x=dates,\n",
    "    y=mean_cluster_ten,\n",
    "    mode='lines',\n",
    "    line=dict(color='red'),\n",
    "    fillcolor='rgba(255,10,240, 0.5)',\n",
    "    fill='tonexty')\n",
    "\n",
    "lower_bound10 = go.Scatter(\n",
    "    name='Lower Bound Cluster 10',\n",
    "    x=dates,\n",
    "    y=mean_cluster_ten-std_cluster_ten,\n",
    "    marker=dict(color=\"#50\"),\n",
    "    line=dict(width=0),\n",
    "    mode='lines')\n",
    "\n",
    "\n",
    "# Trace order can be important\n",
    "# with continuous error bars\n",
    "data = [lower_bound1, trace1, upper_bound1, lower_bound2, trace2, upper_bound2, lower_bound3, trace3, upper_bound3, lower_bound4, trace4, upper_bound4, lower_bound5, trace5, upper_bound5]\n",
    "layout = go.Layout(\n",
    "    yaxis=dict(title='Normalised Number of Prescriptions'),\n",
    "    title='Cluster Comparison - Tramadol',\n",
    "    showlegend = True)\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='pandas-continuous-error-bars')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is a clustering using only the last 3 years of data.\n",
    "Cluster 2 and 3 are interesting in that it appears to be showing an increase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interested_practices_indexes = []\n",
    "\n",
    "for i, j in enumerate(b):\n",
    "    if j == 2:\n",
    "        interested_practices_indexes.append(i)\n",
    "\n",
    "interested_practices_names = []\n",
    "\n",
    "for i in interested_practices_indexes:\n",
    "    name = ninety_practices[i]\n",
    "    interested_practices_names.append(name)\n",
    "\n",
    "print(f\"The practices belonging to cluster 2 are {interested_practices_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "practice_data = pd.read_csv('data/practice_data.csv', names=['a', 'code', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "postcodes = []\n",
    "for code in interested_practices_names:\n",
    "    postcode = practice_data.h[practice_data.code == code]\n",
    "    postcodes.append(postcode)\n",
    "\n",
    "     \n",
    "for i in postcodes:\n",
    "    fullStr = ' '.join(i)\n",
    "    print(fullStr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
